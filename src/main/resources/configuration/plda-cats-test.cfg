# Configuration file used for the paper "Theoretical and Empirical 
# Evaluation of a Grouped Gibbs Sampler for Parallel Computation in 
# the Latent Dirichlet Allocation Model"
#
# Edited on: Jan 12, 2021 
# Created by: Clint P. George 
# 
# Edited on: Jul 12, 2021; Oct 25, 2021; Jul 14, 2022  
# Edited by: Clint P. George 
#
# Ref: Configuration-README.txt

configs = adlda,cgs,pcgs,pcgs-old,ggs
no_runs = 1
experiment_out_dir = /Users/clint/plda/runs/cats # expects a valid path
exec_time = 1800 # in seconds 
iterations = 200
topics = 3
alpha = 5
beta = 7
stoplist = stoplist-empty.txt
dataset = /Users/clint/plda/runs/cats.txt
rare_threshold = 0
keep_numbers = true
seed = 2019
symmetric_alpha = true
hyperparam_optim_interval = -1 # No hyperparameter optimization
# Print N Docs interval: make sure that start_diagnostic is set 
# List the interval in which theta should be printed for the "print_ndocs_cnt" number of documents
print_ndocs_interval = -1 # 1,10000000
print_ndocs_cnt = 0 # 23 # Print theta for all 23 documents
batches = 10
topic_batches = 3
topic_interval = 1
start_diagnostic = 1
debug = 0
log_type_topic_density = false
log_document_density = false
log_phi_density = false
save_doc_lengths = false # Must be set for doc_lengths_file to be created
doc_lengths_filename = doc-lengths.txt
save_term_frequencies = false # Save the number of times individual words occur in entire corpus
term_frequencies_filename = term-frequencies.txt
save_vocabulary = false # Save the vocabulary used (after, stop words, rare words, etc...), order is the same as in Phi
vocabulary_filename = lda-vocab.txt
compute_likelihood = false
# Save the a file with document topic theta estimates (will not include zeros)
# Unlike Phi means which are sampled with thinning, theta means is just a simple
# average of the topic counts in the last iteration divided by the number of 
# tokens in the document thus there is not theta_burnin or theta_thinning
save_doc_theta_estimate = false
doc_topic_theta_filename = doc_topic_theta.csv
# Percent burn in (i.e percent of total number of iterations) before start sampling phi mean
# Example: iterations = 2000, phi_mean_burning = 50 => start sampling Phi at 1000 iterations
phi_mean_burnin = 10
# Phi mean thinning, number of iteration between each Phi sample
phi_mean_thin = 1
# Save Phi means, must be set for output to be created
save_phi_means = false
phi_mean_filename = phi_means.csv
print_phi = false
save_phi = false

[cgs]
title = Collapsed Gibbs Sampler (Serial)
description = Serial collapsed LDA on the Wikipedia dataset: Cats  
scheme = collapsed

[ggs]
title = LDA Grouped Gibbs Sampler
description = Parallel LDA Grouped Gibbs Sampler on the Wikipedia dataset: Cats   
scheme = ggs

[pcgs]
title = LDA Partially Collapsed Gibbs Sampler
description = Partially Collapsed LDA on the Wikipedia dataset: Cats  
scheme = pcgs

[pcgs-old]
title = LDA Partially Collapsed Gibbs Sampler (Old)
description = Uncollapsed parallel LDA on the Wikipedia dataset: Cats  
scheme = uncollapsed

[adlda]
title = ADLDA
description = AD LDA on the Wikipedia dataset: Cats  
scheme = adlda
