configs = ggs
# configs = ggs,UncollapsedPLDA
#configs = SerialCollapsedLDA,UncollapsedPLDA,ADLDA
no_runs = 1
experiment_out_dir = CompTest

[ggs]
title = LDA Grouped Gibbs Sampler
description = Parallel LDA Grouped Gibbs Sampler on the selected dataset. 
scheme = ggs
dataset = src/main/resources/datasets/nips.txt
iterations = 10000
topics = 100
alpha = 1.0
beta = 0.01
batches = 6
rare_threshold = 3
topic_interval = 10
start_diagnostic = 10
debug = 0
log_type_topic_density = true
log_document_density = true
log_phi_density = true
phi_mean_filename = phi-mean.csv
phi_mean_burnin = 10
phi_mean_thin = 1
stoplist = stoplist.txt
seed = 2019
symmetric_alpha = true
hyperparam_optim_interval = -1 # No hyperparameter optimization
save_doc_lengths = true # Must be set for doc_lengths_file to be created
doc_lengths_filename = doc-lengths.txt
save_term_frequencies = true # Save the number of times individual words occur in entire corpus
term_frequencies_filename = term-frequencies.txt
save_vocabulary = true # Save the vocabulary used (after, stop words, rare words, etc...), order is the same as in Phi
vocabulary_filename = lda-vocab.txt



[UncollapsedPLDA]
title = UncollapsedPLDA
description = Uncollapsed parallel LDA on the selected dataset. 
scheme = uncollapsed
dataset = src/main/resources/datasets/nips.txt
iterations = 10000
topics = 100
alpha = 1.0
beta = 0.01
batches = 6
rare_threshold = 3
topic_interval = 10
start_diagnostic = 10
debug = 0
log_type_topic_density = true
log_document_density = true
log_phi_density = true
phi_mean_filename = phi-mean.csv
phi_mean_burnin = 10
phi_mean_thin = 1
stoplist = stoplist.txt
seed = 2019
symmetric_alpha = true
hyperparam_optim_interval = -1 # No hyperparameter optimization
save_doc_lengths = true # Must be set for doc_lengths_file to be created
doc_lengths_filename = doc-lengths.txt
save_term_frequencies = true # Save the number of times individual words occur in entire corpus
term_frequencies_filename = term-frequencies.txt
save_vocabulary = true # Save the vocabulary used (after, stop words, rare words, etc...), order is the same as in Phi
vocabulary_filename = lda-vocab.txt




[ADLDA]
title = ADLDA
description = AD LDA on selected dataset
#dataset = src/main/resources/datasets/ap.txt
dataset = src/main/resources/datasets/nips.txt
#dataset = src/main/resources/datasets/enron.txt
#dataset = src/main/resources/datasets/pubmed.txt
scheme = adlda
iterations = 10000
topics = 100
alpha = 1.0
beta = 0.01
batches = 6
rare_threshold = 3
topic_interval = 10
start_diagnostic = 10
debug = 0
log_type_topic_density = true
log_document_density = true
log_phi_density = true
phi_mean_filename = phi-mean.csv
phi_mean_burnin = 10
phi_mean_thin = 1
stoplist = stoplist.txt
seed = 2019
symmetric_alpha = true
hyperparam_optim_interval = -1 # No hyperparameter optimization
save_doc_lengths = true # Must be set for doc_lengths_file to be created
doc_lengths_filename = doc-lengths.txt
save_term_frequencies = true # Save the number of times individual words occur in entire corpus
term_frequencies_filename = term-frequencies.txt
save_vocabulary = true # Save the vocabulary used (after, stop words, rare words, etc...), order is the same as in Phi
vocabulary_filename = lda-vocab.txt


[SerialCollapsedLDA]
title = SerialCollapsedLDA
description = Serial collapsed LDA on the selected dataset. 
dataset = src/main/resources/datasets/nips.txt
scheme = collapsed
iterations = 10000
topics = 100
alpha = 1.0
beta = 0.01
batches = 6
rare_threshold = 3
topic_interval = 10
start_diagnostic = 10
debug = 0
log_type_topic_density = true
log_document_density = true
log_phi_density = true
phi_mean_filename = phi-mean.csv
phi_mean_burnin = 10
phi_mean_thin = 1
stoplist = stoplist.txt
seed = 2019
symmetric_alpha = true
hyperparam_optim_interval = -1 # No hyperparameter optimization
save_doc_lengths = true # Must be set for doc_lengths_file to be created
doc_lengths_filename = doc-lengths.txt
save_term_frequencies = true # Save the number of times individual words occur in entire corpus
term_frequencies_filename = term-frequencies.txt
save_vocabulary = true # Save the vocabulary used (after, stop words, rare words, etc...), order is the same as in Phi
vocabulary_filename = lda-vocab.txt





[Spalias]
title = PCPLDA
description = PCP LDA on selected dataset
#dataset = src/main/resources/datasets/ap.txt
dataset = src/main/resources/datasets/nips.txt
#dataset = src/main/resources/datasets/enron.txt
#dataset = src/main/resources/datasets/pubmed.txt
scheme = spalias
iterations = 100
topics = 20
alpha = 1.0
beta = 0.01
batches = 4
rare_threshold = 3
topic_interval = 50
start_diagnostic = 10
debug = 0
log_type_topic_density = true
log_document_density = true
log_phi_density = true
phi_mean_filename = phi-mean.csv
phi_mean_burnin = 10
phi_mean_thin = 1
stoplist = stoplist.txt
seed = 2019







[ggs2]
title = LDA Grouped Gibbs Sampler with Sparse Topic Dirichlet Sampling
description = Parallel LDA Grouped Gibbs Sampler with Sparse Topic Dirichlet Sampling on the selected dataset. 
scheme = ggs2
dataset = src/main/resources/datasets/nips.txt
iterations = 10000
topics = 100
alpha = 1.0
beta = 0.01
batches = 6
rare_threshold = 3
topic_interval = 50
start_diagnostic = 10
debug = 0
log_type_topic_density = true
log_document_density = true
log_phi_density = true
phi_mean_filename = phi-mean.csv
phi_mean_burnin = 10
phi_mean_thin = 1
stoplist = stoplist.txt
seed = 2019
symmetric_alpha = true
# No hyperparameter optimization 
hyperparam_optim_interval = -1
# Must be set for doc_lengths_file to be created
save_doc_lengths = true
doc_lengths_filename = doc-lengths.txt
# Save the number of times individual words occur in entire corpus
save_term_frequencies = true
term_frequencies_filename = term-frequencies.txt
# Save the vocabulary used (after, stop words, rare words, etc...)
# Order is the same as in Phi
save_vocabulary = true
vocabulary_filename = lda-vocab.txt