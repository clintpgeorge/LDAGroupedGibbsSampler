# Configuration file used for the paper "Theoretical and Empirical 
# Evaluation of a Grouped Gibbs Sampler for Parallel Computation in 
# the Latent Dirichlet Allocation Model"
#
# Edited on: Jan 12, 2021 
# Created by: Clint P. George 
# 
# Ref: Configuration-README.txt

configs = ggs
# configs = ggs,UncollapsedPLDA
#configs = SerialCollapsedLDA,UncollapsedPLDA,ADLDA
no_runs = 1
experiment_out_dir = plda

[ggs]
title = LDA Grouped Gibbs Sampler
description = Parallel LDA Grouped Gibbs Sampler on a 'dataset' given. 
scheme = ggs
dataset = src/main/resources/datasets/nips.txt
iterations = 10000
topics = 100
alpha = 1.0
beta = 0.01
batches = 6
topic_batches = 3
rare_threshold = 3
topic_interval = 10
start_diagnostic = 10
debug = 0
log_type_topic_density = true
log_document_density = true
log_phi_density = true
phi_mean_filename = phi-mean.csv
phi_mean_burnin = 10
phi_mean_thin = 1
stoplist = stoplist.txt
seed = 2019
symmetric_alpha = true
hyperparam_optim_interval = -1 # No hyperparameter optimization
save_doc_lengths = true # Must be set for doc_lengths_file to be created
doc_lengths_filename = doc-lengths.txt
save_term_frequencies = true # Save the number of times individual words occur in entire corpus
term_frequencies_filename = term-frequencies.txt
save_vocabulary = true # Save the vocabulary used (after, stop words, rare words, etc...), order is the same as in Phi
vocabulary_filename = lda-vocab.txt



[UncollapsedPLDA]
title = UncollapsedPLDA
description = Uncollapsed parallel LDA on the selected dataset. 
scheme = uncollapsed
dataset = src/main/resources/datasets/nips.txt
iterations = 10000
topics = 100
alpha = 1.0
beta = 0.01
batches = 6
rare_threshold = 3
topic_interval = 10
start_diagnostic = 10
debug = 0
log_type_topic_density = true
log_document_density = true
log_phi_density = true
phi_mean_filename = phi-mean.csv
phi_mean_burnin = 10
phi_mean_thin = 1
stoplist = stoplist.txt
seed = 2019
symmetric_alpha = true
hyperparam_optim_interval = -1 # No hyperparameter optimization
save_doc_lengths = true # Must be set for doc_lengths_file to be created
doc_lengths_filename = doc-lengths.txt
save_term_frequencies = true # Save the number of times individual words occur in entire corpus
term_frequencies_filename = term-frequencies.txt
save_vocabulary = true # Save the vocabulary used (after, stop words, rare words, etc...), order is the same as in Phi
vocabulary_filename = lda-vocab.txt




[ADLDA]
title = ADLDA
description = AD LDA on selected dataset
#dataset = src/main/resources/datasets/ap.txt
dataset = src/main/resources/datasets/nips.txt
#dataset = src/main/resources/datasets/enron.txt
#dataset = src/main/resources/datasets/pubmed.txt
scheme = adlda
iterations = 10000
topics = 100
alpha = 1.0
beta = 0.01
batches = 6
rare_threshold = 3
topic_interval = 10
start_diagnostic = 10
debug = 0
log_type_topic_density = true
log_document_density = true
log_phi_density = true
phi_mean_filename = phi-mean.csv
phi_mean_burnin = 10
phi_mean_thin = 1
stoplist = stoplist.txt
seed = 2019
symmetric_alpha = true
hyperparam_optim_interval = -1 # No hyperparameter optimization
save_doc_lengths = true # Must be set for doc_lengths_file to be created
doc_lengths_filename = doc-lengths.txt
save_term_frequencies = true # Save the number of times individual words occur in entire corpus
term_frequencies_filename = term-frequencies.txt
save_vocabulary = true # Save the vocabulary used (after, stop words, rare words, etc...), order is the same as in Phi
vocabulary_filename = lda-vocab.txt


[SerialCollapsedLDA]
title = SerialCollapsedLDA
description = Serial collapsed LDA on the selected dataset. 
dataset = src/main/resources/datasets/nips.txt
scheme = collapsed
iterations = 10000
topics = 100
alpha = 1.0
beta = 0.01
batches = 6
rare_threshold = 3
topic_interval = 10
start_diagnostic = 10
debug = 0
log_type_topic_density = true
log_document_density = true
log_phi_density = true
phi_mean_filename = phi-mean.csv
phi_mean_burnin = 10
phi_mean_thin = 1
stoplist = stoplist.txt
seed = 2019
symmetric_alpha = true
hyperparam_optim_interval = -1 # No hyperparameter optimization
save_doc_lengths = true # Must be set for doc_lengths_file to be created
doc_lengths_filename = doc-lengths.txt
save_term_frequencies = true # Save the number of times individual words occur in entire corpus
term_frequencies_filename = term-frequencies.txt
save_vocabulary = true # Save the vocabulary used (after, stop words, rare words, etc...), order is the same as in Phi
vocabulary_filename = lda-vocab.txt




