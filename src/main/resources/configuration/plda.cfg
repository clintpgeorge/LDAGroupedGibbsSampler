# Configuration file used for the paper "Theoretical and Empirical 
# Evaluation of a Grouped Gibbs Sampler for Parallel Computation in 
# the Latent Dirichlet Allocation Model"
#
# Edited on: Jan 12, 2021 
# Created by: Clint P. George 
# 
# Ref: Configuration-README.txt

#configs = cgs
configs = cgs,pcgs,ggs,adlda
no_runs = 1
experiment_out_dir = plda

[ggs]
title = LDA Grouped Gibbs Sampler
description = Parallel LDA Grouped Gibbs Sampler on a 'dataset' given. 
scheme = ggs
dataset = src/main/resources/datasets/nips.txt
iterations = 100
topics = 50
alpha = 1.0
beta = 0.01
batches = 1
topic_batches = 1
rare_threshold = 3
topic_interval = 10
start_diagnostic = 10
debug = 0
log_type_topic_density = false
log_document_density = false
log_phi_density = false
phi_mean_filename = phi-mean.csv
phi_mean_burnin = 10
phi_mean_thin = 1
stoplist = stoplist.txt
seed = 2019
symmetric_alpha = true
hyperparam_optim_interval = -1 # No hyperparameter optimization
save_doc_lengths = false # Must be set for doc_lengths_file to be created
doc_lengths_filename = doc-lengths.txt
save_term_frequencies = false # Save the number of times individual words occur in entire corpus
term_frequencies_filename = term-frequencies.txt
save_vocabulary = false # Save the vocabulary used (after, stop words, rare words, etc...), order is the same as in Phi
vocabulary_filename = lda-vocab.txt
compute_likelihood = false



[pcgs]
title = LDA Partially Collapsed Gibbs Sampler
description = Uncollapsed parallel LDA on the selected dataset. 
scheme = uncollapsed
dataset = src/main/resources/datasets/nips.txt
iterations = 100
topics = 50
alpha = 1.0
beta = 0.01
batches = 1
topic_batches = 1
rare_threshold = 3
topic_interval = 10
start_diagnostic = 10
debug = 0
log_type_topic_density = true
log_document_density = true
log_phi_density = true
phi_mean_filename = phi-mean.csv
phi_mean_burnin = 10
phi_mean_thin = 1
stoplist = stoplist.txt
seed = 2019
symmetric_alpha = true
hyperparam_optim_interval = -1 # No hyperparameter optimization
save_doc_lengths = true # Must be set for doc_lengths_file to be created
doc_lengths_filename = doc-lengths.txt
save_term_frequencies = true # Save the number of times individual words occur in entire corpus
term_frequencies_filename = term-frequencies.txt
save_vocabulary = true # Save the vocabulary used (after, stop words, rare words, etc...), order is the same as in Phi
vocabulary_filename = lda-vocab.txt
compute_likelihood = false




[adlda]
title = ADLDA
description = AD LDA on selected dataset
#dataset = src/main/resources/datasets/ap.txt
dataset = src/main/resources/datasets/nips.txt
#dataset = src/main/resources/datasets/enron.txt
#dataset = src/main/resources/datasets/pubmed.txt
scheme = adlda
iterations = 100
topics = 50
alpha = 1.0
beta = 0.01
batches = 1
topic_batches = 1
rare_threshold = 3
topic_interval = 10
start_diagnostic = 10
debug = 0
log_type_topic_density = true
log_document_density = true
log_phi_density = true
phi_mean_filename = phi-mean.csv
phi_mean_burnin = 10
phi_mean_thin = 1
stoplist = stoplist.txt
seed = 2019
symmetric_alpha = true
hyperparam_optim_interval = -1 # No hyperparameter optimization
save_doc_lengths = true # Must be set for doc_lengths_file to be created
doc_lengths_filename = doc-lengths.txt
save_term_frequencies = true # Save the number of times individual words occur in entire corpus
term_frequencies_filename = term-frequencies.txt
save_vocabulary = true # Save the vocabulary used (after, stop words, rare words, etc...), order is the same as in Phi
vocabulary_filename = lda-vocab.txt
compute_likelihood = false


[cgs]
title = Collapsed Gibbs Sampler (Serial)
description = Serial collapsed LDA on the selected dataset. 
dataset = src/main/resources/datasets/nips.txt
scheme = collapsed
iterations = 100
topics = 50
alpha = 1.0
beta = 0.01
batches = 1
topic_batches = 1
rare_threshold = 3
topic_interval = 10
start_diagnostic = 10
debug = 0
log_type_topic_density = true
log_document_density = true
log_phi_density = true
phi_mean_filename = phi-mean.csv
phi_mean_burnin = 10
phi_mean_thin = 1
stoplist = stoplist.txt
seed = 2019
symmetric_alpha = true
hyperparam_optim_interval = -1 # No hyperparameter optimization
save_doc_lengths = true # Must be set for doc_lengths_file to be created
doc_lengths_filename = doc-lengths.txt
save_term_frequencies = true # Save the number of times individual words occur in entire corpus
term_frequencies_filename = term-frequencies.txt
save_vocabulary = true # Save the vocabulary used (after, stop words, rare words, etc...), order is the same as in Phi
vocabulary_filename = lda-vocab.txt
compute_likelihood = false




